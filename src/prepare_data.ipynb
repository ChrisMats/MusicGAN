{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "This script loads the Speech Commands dataset, builds the SC09 dataset (discards all samples except for\n",
    "the utterances from 0 to 9), preprocesses the data and saves it to a designated folder as TFRecords. \n",
    "\n",
    "Note, in order to not discard the 0-9 utterances they must be in folders named 'zero', 'one', 'two', etc.\n",
    "within the Speech Command dataset folder.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "__author__ = \"Matthaios Stylianidis\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Move these functions to utils.py and import them\n",
    "from pysndfile import sndio\n",
    "import numpy as np\n",
    "\n",
    "def load_audio(file_path):\n",
    "    \"\"\"Loads audio data from wav file using pysndfile.\n",
    "\n",
    "    Args:\n",
    "        file_path: Path to a wav file.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing the samples and the sampling rate of the\n",
    "        wav file, in this order.\n",
    "    \"\"\"\n",
    "    data = sndio.read(file_path)\n",
    "    sampling_rate = data[1]\n",
    "    samples = np.array(data[0], dtype=np.float32)\n",
    "    return samples, sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arguments():\n",
    "    \"\"\"Parse all the arguments provided from the CLI.\n",
    "    \n",
    "    Returns:\n",
    "      A list of parsed arguments.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(description=\"Dataset preprocessing.\")\n",
    "    parser.add_argument(\"img_path\", type=str,\n",
    "                        help=\"Path to the RGB image file.\")\n",
    "    parser.add_argument(\"img_path\", type=str,\n",
    "                        help=\"Path to the RGB image file.\")\n",
    "    return parser.parse_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_DATASET_PATH = './SpeechCommands/' # Default Speech Commands dataset path \n",
    "DEFAULT_PREPROCESSED_DATASET_PATH = './SC09_Preprocessed/' # Default path to save preprocessed data\n",
    "DEFAULT_FIXED_SIGNAL_SIZE = 16384\n",
    "RANDOM_PADDING = False\n",
    "\n",
    "# Folders with 0-9 classes in speech commands\n",
    "class_folders = [ 'zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight','nine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#args = get_arguments()\n",
    "#print(args.accumulate(args.integers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory for saving the pre-processed data if it does not exist\n",
    "if not os.path.exists(DEFAULT_PREPROCESSED_DATASET_PATH):\n",
    "    os.makedirs(DEFAULT_PREPROCESSED_DATASET_PATH)\n",
    "    print(\"Created \" + DEFAULT_PREPROCESSED_DATASET_PATH + \" directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the tensorflow preprocessing graph\n",
    "audio_file_name = tf.placeholder(tf.string, [])\n",
    "\n",
    "# Create tf operation that loads audio and returns samples and sampling rate\n",
    "audio_samples, audio_sampling_freq = tf.py_func(load_audio, [audio_file_name], [tf.float32, tf.int64], \\\n",
    "                                               name='Data_loading') \n",
    "\n",
    "# Constant for desired signal size after cropping or padding\n",
    "fixed_signal_size = tf.constant(DEFAULT_FIXED_SIGNAL_SIZE)\n",
    "\n",
    "# Preprocess audio\n",
    "if RANDOM_PADDING:\n",
    "    # Crop sides if larger than fixed length, insert random padding otherwise\n",
    "    #preprocessed_samples = tf.py_func(crop_or_random_pad, [audio_samples, fixed_signal_size], tf.float32)\n",
    "    pass\n",
    "else:\n",
    "    # Crop sides if larger than fixed length, pad the sides of the signal symmetrically if not large enough\n",
    "    tensor_height = tf.constant(1)\n",
    "    reshaped_samples = tf.reshape(audio_samples, [1, -1])\n",
    "    preprocessed_samples = tf.image.resize_image_with_crop_or_pad(reshaped_samples, tensor_height, fixed_signal_size)\n",
    "    pass\n",
    "\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each folder in the dataset folder\n",
    "sample_count = 0\n",
    "for folder_name in os.listdir(DEFAULT_DATASET_PATH):\n",
    "    # Ommit the folder if its name does not correspond to 0-9 digits.\n",
    "    if folder_name not in class_folders:\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    new_folder_path = DEFAULT_PREPROCESSED_DATASET_PATH + folder_name + '/'\n",
    "    # Create folder with the same name in saving directory\n",
    "    if not os.path.exists(new_folder_path):\n",
    "        os.makedirs(new_folder_path)\n",
    "        print(\"Created \" + new_folder_path + \" directory.\")\n",
    "    \n",
    "    # Create TFRecord writer\n",
    "    writer = tf.python_io.TFRecordWriter(new_folder_path + 'train.tfrecords')\n",
    "    \n",
    "    folder_path = DEFAULT_DATASET_PATH + folder_name + \"/\"\n",
    "    print(\"Preprocessing samples from folder \" + folder_path + \".\")\n",
    "    folder_file_count = 0\n",
    "    for wav_file_name in tqdm(os.listdir(folder_path)):\n",
    "        # Make ndarray with wav file path\n",
    "        load_file_path = np.array(folder_path + wav_file_name)\n",
    "        # Load and process the wav file using tensorflow\n",
    "        preprocessed_data = sess.run(preprocessed_samples, feed_dict = {audio_file_name: load_file_path})\n",
    "        print(preprocessed_data.shape)\n",
    "        # Create a feature \n",
    "        feature = {'train/signal': _bytes_feature(tf.compat.as_bytes(preprocessed_data.tostring()))}\n",
    "        # Create example protocol buffer\n",
    "        exmple_protocol_buff = tf.train.Example(features=tf.train.Features(feature = feature))\n",
    "        # Serialize to string and write to file\n",
    "        writer.write(exmple_protocol_buff.SerializeToString())\n",
    "        # Increase count of current class files by 1\n",
    "        folder_file_count += 1\n",
    "    \n",
    "    # Close TFRecord writer\n",
    "    writer.close()\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    # Increase count of samples processed\n",
    "    sample_count += folder_file_count\n",
    "    \n",
    "    print(str(folder_file_count) + \" samples from folder \" + folder_path + \\\n",
    "          \" have been preprocessed and saved in \" + \\\n",
    "          DEFAULT_PREPROCESSED_DATASET_PATH + folder_name + \".\\n\")\n",
    "    \n",
    "print(\"Loaded \" + str(sample_count) + \" wav files.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
