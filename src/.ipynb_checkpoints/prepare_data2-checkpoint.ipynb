{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'util'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-9ad905280cf4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'util'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "This script loads the Speech Commands dataset, builds the SC09 dataset (discards all samples except for\n",
    "the utterances from 0 to 9), preprocesses the data and saves it to a designated folder as TFRecords. \n",
    "\n",
    "Note, in order to not discard the 0-9 utterances they must be in folders named 'zero', 'one', 'two', etc.\n",
    "within the Speech Command dataset folder.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from util import *\n",
    "\n",
    "\n",
    "\n",
    "__author__ = \"Matthaios Stylianidis\"\n",
    "\n",
    "DEFAULT_DATASET_PATH = '../../SpeechCommands/' # Default Speech Commands dataset path \n",
    "DEFAULT_PREPROCESSED_DATASET_PATH = '../../SC09_Preprocessed/' # Default path to save preprocessed data\n",
    "DEFAULT_FIXED_SIGNAL_SIZE = 16384\n",
    "RANDOM_PADDING = False\n",
    "\n",
    "\n",
    "def _bytes_feature(value):\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def get_arguments():\n",
    "    \"\"\"Parse all the arguments provided from the CLI.\n",
    "    \n",
    "    Returns:\n",
    "      A list of parsed arguments.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(description=\"Dataset preprocessing.\")\n",
    "    parser.add_argument(\"img_path\", type=str,\n",
    "                        help=\"Path to the RGB image file.\")\n",
    "    parser.add_argument(\"img_path\", type=str,\n",
    "                        help=\"Path to the RGB image file.\")\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "\n",
    "# Folders with 0-9 classes in speech commands\n",
    "class_folders = ['zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight','nine']\n",
    "\n",
    "#args = get_arguments()\n",
    "#print(args.accumulate(args.integers))\n",
    "\n",
    "# Create directory for saving the pre-processed data if it does not exist\n",
    "if not os.path.exists(DEFAULT_PREPROCESSED_DATASET_PATH):\n",
    "    os.makedirs(DEFAULT_PREPROCESSED_DATASET_PATH)\n",
    "    print(\"Created \" + DEFAULT_PREPROCESSED_DATASET_PATH + \" directory.\")\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "# Build the tensorflow preprocessing graph\n",
    "audio_file_name = tf.placeholder(tf.string, [])\n",
    "\n",
    "# Create tf operation that loads audio and returns samples and sampling rate\n",
    "audio_samples, audio_sampling_freq = tf.py_func(load_audio, [audio_file_name], [tf.float32, tf.int64], \\\n",
    "                                               name='Data_loading') \n",
    "\n",
    "# Constant for desired signal size after cropping or padding\n",
    "fixed_signal_size = tf.constant(DEFAULT_FIXED_SIGNAL_SIZE)\n",
    "\n",
    "# Preprocess audio\n",
    "if RANDOM_PADDING:\n",
    "    # Crop sides if larger than fixed length, insert random padding otherwise\n",
    "    #preprocessed_samples = tf.py_func(crop_or_random_pad, [audio_samples, fixed_signal_size], tf.float32)\n",
    "    pass\n",
    "else:\n",
    "    # Crop sides if larger than fixed length, pad the sides of the signal symmetrically if not large enough\n",
    "    tensor_height = tf.constant(1)\n",
    "    reshaped_samples = tf.reshape(audio_samples, [1, tf.size(audio_samples), -1])\n",
    "    preprocessed_samples = tf.image.resize_image_with_crop_or_pad(reshaped_samples, tensor_height, fixed_signal_size)\n",
    "    preprocessed_samples = tf.reshape(preprocessed_samples, [1, fixed_signal_size])\n",
    "    pass\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# For each folder in the dataset folder\n",
    "sample_count = 0\n",
    "for folder_name in os.listdir(DEFAULT_DATASET_PATH):\n",
    "    # Ommit the folder if its name does not correspond to 0-9 digits.\n",
    "    if folder_name not in class_folders:\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    new_folder_path = DEFAULT_PREPROCESSED_DATASET_PATH + folder_name + '/'\n",
    "    # Create folder with the same name in saving directory\n",
    "    if not os.path.exists(new_folder_path):\n",
    "        os.makedirs(new_folder_path)\n",
    "        print(\"Created \" + new_folder_path + \" directory.\")\n",
    "    \n",
    "    # Create TFRecord writer\n",
    "    writer = tf.python_io.TFRecordWriter(new_folder_path + 'train.tfrecords')\n",
    "    \n",
    "    folder_path = DEFAULT_DATASET_PATH + folder_name + \"/\"\n",
    "    print(\"Preprocessing samples from folder \" + folder_path + \".\")\n",
    "    folder_file_count = 0\n",
    "    for wav_file_name in tqdm(os.listdir(folder_path)):\n",
    "        # Make ndarray with wav file path\n",
    "        load_file_path = np.array(folder_path + wav_file_name)\n",
    "        # Load and process the wav file using tensorflow\n",
    "        preprocessed_data = sess.run(preprocessed_samples, feed_dict = {audio_file_name: load_file_path})\n",
    "        \n",
    "        # Create a feature \n",
    "        feature = {'train/signal': _bytes_feature(tf.compat.as_bytes(preprocessed_data.tostring()))}\n",
    "        # Create example protocol buffer\n",
    "        exmple_protocol_buff = tf.train.Example(features=tf.train.Features(feature = feature))\n",
    "        # Serialize to string and write to file\n",
    "        writer.write(exmple_protocol_buff.SerializeToString())\n",
    "        # Increase count of current class files by 1\n",
    "        folder_file_count += 1\n",
    "    \n",
    "    # Close TFRecord writer\n",
    "    writer.close()\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    # Increase count of samples processed\n",
    "    sample_count += folder_file_count\n",
    "    \n",
    "    print(str(folder_file_count) + \" samples from folder \" + folder_path + \\\n",
    "          \" have been preprocessed and saved in \" + \\\n",
    "          DEFAULT_PREPROCESSED_DATASET_PATH + folder_name + \".\\n\")\n",
    "    \n",
    "print(\"Loaded \" + str(sample_count) + \" wav files.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
